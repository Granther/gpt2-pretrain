{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f970d9bf-180c-4e30-932a-dbdd22eef81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ead81f8f-b0e2-44d2-aa0d-bc66105f1329",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyper Params\n",
    "batch_size = 1\n",
    "hidden_size = 120\n",
    "input_size = 120\n",
    "embed_dim = 120\n",
    "lr = 0.001\n",
    "epochs = 50\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0c6db8d-1973-46bf-9e46-5b790efd56b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = load_dataset(\"jaydenccc/AI_Storyteller_Dataset\", split=\"train\")['short_story']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b889e196-d6a1-4fca-9c89-6e3c753e337d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /home/grant/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "\n",
    "text_corpus = \"\"\n",
    "for item in raw_dataset:\n",
    "    text_corpus += item.lower()\n",
    "\n",
    "text_corpus = text_corpus.replace('.', '').replace(',','').replace('\\n',' ').replace('\\'', '').replace('\\\"', '').replace(':', '').replace('?', '').replace('!', '').replace(';', '').replace('-', '')\n",
    "\n",
    "tokens = word_tokenize(text_corpus)\n",
    "tokens = [item for item in tokens if item not in ['the', '']]\n",
    "\n",
    "unique_words = set(tokens)\n",
    "word_to_num = {word: idx for idx, word in enumerate(unique_words)}\n",
    "num_to_word = {idx: word for idx, word in enumerate(unique_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b6fd7f9-58a7-47a5-9c6d-bbeee9b36698",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = len(word_to_num)\n",
    "\n",
    "pad_tok_id = output_size\n",
    "num_to_word[pad_tok_id] = '<pad>'\n",
    "word_to_num['<pad>'] = pad_tok_id\n",
    "\n",
    "num_to_word[output_size+1] = ''\n",
    "word_to_num[''] = output_size+1\n",
    "\n",
    "output_size = len(word_to_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "636a65fe-5b54-4f62-81a1-93a8744b7c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StoryDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cabc52ba-4148-4020-a043-a7190e130852",
   "metadata": {},
   "outputs": [],
   "source": [
    "pads = ['<pad>' for i in range(9)]\n",
    "corpus = text_corpus.split(' ')\n",
    "corpus = [item for item in corpus if item not in ['the', '']]\n",
    "\n",
    "train_dataset = StoryDataset(corpus[:25000])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "test_dataset = StoryDataset(corpus[25000:])\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "856c0b85-a19c-4b22-ba78-6abab9d9ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, output_size, embed_dim, vocab_size):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 120),\n",
    "            nn.GELU(),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(120, 240),\n",
    "            nn.GELU(),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(240, output_size)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        embedded = self.embed(x)\n",
    "        embedded = embedded.view(embedded.size(0), -1)\n",
    "        return self.fc(embedded)\n",
    "        # return torch.argmax(x, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37fa4c9a-8494-4364-b780-9f815ee6f1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size, output_size, embed_dim, len(num_to_word)).to(device)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(net.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d08c2ca9-ee85-42b5-8c52-c792937ef1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 6.903551365067418, Epoch: 1/50\n",
      "Loss: 6.689913034522072, Epoch: 2/50\n",
      "Loss: 6.563159259649946, Epoch: 3/50\n",
      "Loss: 6.380579395937433, Epoch: 4/50\n",
      "Loss: 6.2008056386745185, Epoch: 5/50\n",
      "Loss: 6.061294905322877, Epoch: 6/50\n",
      "Loss: 5.938598689933577, Epoch: 7/50\n",
      "Loss: 5.846441353606858, Epoch: 8/50\n",
      "Loss: 5.766433396298639, Epoch: 9/50\n",
      "Loss: 5.681622043591896, Epoch: 10/50\n",
      "Loss: 5.624921192635954, Epoch: 11/50\n",
      "Loss: 5.560673291829478, Epoch: 12/50\n",
      "Loss: 5.510109524559659, Epoch: 13/50\n",
      "Loss: 5.455990849814052, Epoch: 14/50\n",
      "Loss: 5.412311597060608, Epoch: 15/50\n",
      "Loss: 5.402452818609428, Epoch: 16/50\n",
      "Loss: 5.371902284716587, Epoch: 17/50\n",
      "Loss: 5.355709599562171, Epoch: 18/50\n",
      "Loss: 5.330054915959479, Epoch: 19/50\n",
      "Loss: 5.318743065410997, Epoch: 20/50\n",
      "Loss: 5.304307303036016, Epoch: 21/50\n",
      "Loss: 5.29314997153857, Epoch: 22/50\n",
      "Loss: 5.274410574701499, Epoch: 23/50\n",
      "Loss: 5.267184158877183, Epoch: 24/50\n",
      "Loss: 5.238924741789027, Epoch: 25/50\n",
      "Loss: 5.2070799644536185, Epoch: 26/50\n",
      "Loss: 5.235889359142448, Epoch: 27/50\n",
      "Loss: 5.208939498411957, Epoch: 28/50\n",
      "Loss: 5.183532868208104, Epoch: 29/50\n",
      "Loss: 5.212650188722946, Epoch: 30/50\n",
      "Loss: 5.128199017283751, Epoch: 31/50\n",
      "Loss: 5.193811215411539, Epoch: 32/50\n",
      "Loss: 5.129907575454189, Epoch: 33/50\n",
      "Loss: 5.177319828126895, Epoch: 34/50\n",
      "Loss: 5.129960494907208, Epoch: 35/50\n",
      "Loss: 5.131240725279688, Epoch: 36/50\n",
      "Loss: 5.101551375889449, Epoch: 37/50\n",
      "Loss: 5.230230484250329, Epoch: 38/50\n",
      "Loss: 5.125704075082316, Epoch: 39/50\n",
      "Loss: 5.150043292775175, Epoch: 40/50\n",
      "Loss: 5.124284249732318, Epoch: 41/50\n",
      "Loss: 5.160949991014454, Epoch: 42/50\n",
      "Loss: 5.059156532981475, Epoch: 43/50\n",
      "Loss: 5.081034545749823, Epoch: 44/50\n",
      "Loss: 5.199783635291101, Epoch: 45/50\n",
      "Loss: 5.241489029852355, Epoch: 46/50\n",
      "Loss: 5.181412020862048, Epoch: 47/50\n",
      "Loss: 5.108233660251702, Epoch: 48/50\n",
      "Loss: 5.160514892345955, Epoch: 49/50\n",
      "Loss: 5.119250915179396, Epoch: 50/50\n"
     ]
    }
   ],
   "source": [
    "avg_loss = 0\n",
    "net.train()\n",
    "for epoch in range(epochs):\n",
    "    for i, item in enumerate(train_dataset):\n",
    "        if i < len(train_dataset) - 1:\n",
    "            opt.zero_grad()\n",
    "            # Prepare input and target\n",
    "            # input_tensor = torch.tensor([[word_to_num[item]]], dtype=torch.long)\n",
    "            # # target_tensor = torch.tensor([word_to_num[train_dataset[i+1]]], dtype=torch.long).to(device)\n",
    "            # target_tensor = torch.zeros(1, 4588, dtype=torch.long)\n",
    "            # target_tensor[0, word_to_num[train_dataset[i+1]]] = 1\n",
    "\n",
    "            # input_tensor, target_tensor = input_tensor.to(device), target_tensor.to(device)\n",
    "\n",
    "            input_tensor = torch.tensor([[word_to_num[item]]], dtype=torch.long).to(device)\n",
    "            target_tensor = torch.tensor([word_to_num[train_dataset[i + 1]]], dtype=torch.long).to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            output = net(input_tensor)\n",
    "            # Compute loss\n",
    "            loss = crit(output, target_tensor)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            avg_loss += loss.item()\n",
    "\n",
    "        # if i % 10000 == 0:\n",
    "        #     print(f'Loss: {avg_loss/10000}, Step: {i}/{len(train_dataset)*epochs}, Epoch: {epoch}/{epochs-1}')\n",
    "        #     avg_loss = 0\n",
    "    \n",
    "    print(f'Loss: {avg_loss/25000}, Epoch: {epoch+1}/{epochs}')\n",
    "    torch.save(net.state_dict(), f\"rnn-nlp-epoch-{epoch}.pth\")\n",
    "    avg_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3ced6b-9c1d-410d-939c-fbe6e458dbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './next_word_2.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "696243c6-5496-4dd4-a5bc-cbc10b11d25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "protecting\n",
      "her\n",
      "that\n",
      "she\n",
      "had\n",
      "to\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n",
      "chain\n",
      "of\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "seq_len = 100\n",
    "seq = []\n",
    "cur = \"protecting\"\n",
    "\n",
    "for i in range(seq_len):\n",
    "    print(cur)\n",
    "    next_tok = net(torch.tensor([[word_to_num[cur]]], dtype=torch.long).to(device))\n",
    "    cur = num_to_word[torch.argmax(next_tok).item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd3c90a9-c246-4846-8e76-6cb2f7a45ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: the\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "input_tensor = torch.tensor([[word_to_num[\"the\"]]], dtype=torch.float32)\n",
    "\n",
    "# Forward pass\n",
    "output = torch.argmax(net(input_tensor))\n",
    "print(f'Word: {num_to_word[output.item()]}')\n",
    "\n",
    "plot = output.detach().numpy()\n",
    "plt.plot(plot)\n",
    "plt.show()\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.bar(range(len(fc1_logits[0])), fc1_logits[0], color='blue', alpha=0.7)\n",
    "# plt.title(\"Logits from fc1 Layer\")\n",
    "# plt.xlabel(\"Neuron Index\")\n",
    "# plt.ylabel(\"Logit Value\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e595e7d8-5cf4-4c6c-9b93-3be26c249e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Init hidden state (batch size * hidden size)\n",
    "        batch_size = x.size(0)\n",
    "        hidden = torch.zeros(1, batch_size, self.hidden_size) # \n",
    "\n",
    "        # Forward through net\n",
    "        out, hidden = self.rnn(x, hidden)\n",
    "\n",
    "        # Only use last hidden state for output\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18fdee43-d2b3-46f1-a180-6a4547705f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Example tensor\n",
    "tensor = torch.rand(1, 4500)  # Shape [1, 4500]\n",
    "\n",
    "# Apply softmax\n",
    "softmax_probs = F.softmax(tensor, dim=1)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Convert to NumPy array\n",
    "softmax_probs_np = softmax_probs.squeeze(0).detach().cpu().numpy()  # Shape [4500]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the top 10 probabilities\n",
    "top_k = 10\n",
    "top_probs, top_indices = torch.topk(softmax_probs, top_k)\n",
    "\n",
    "top_probs_np = top_probs.squeeze(0).detach().cpu().numpy()\n",
    "top_indices_np = top_indices.squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "plt.bar(range(top_k), top_probs_np, tick_label=top_indices_np)\n",
    "plt.title(\"Top 10 Probabilities\")\n",
    "plt.xlabel(\"Indices\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
